# RAG Chatbot - AnalÃ½za a Diagnostika

**Datum:** 6. prosince 2025
**Status:** âš ï¸ NEFUNKÄŒNÃ - VyÅ¾aduje opravu

---

## ğŸ” ZjiÅ¡tÄ›nÃ© ProblÃ©my

### 1. âŒ KRITICKÃ‰: DatabÃ¡zovÃ© PÅ™ipojenÃ­ SelhÃ¡vÃ¡

**Chyba:**
```
connection to server at "aws-0-eu-central-1.pooler.supabase.com" failed:
FATAL: Tenant or user not found
```

**PÅ™Ã­Äina:**
- Soubor `.env.local` obsahuje **neplatnÃ© nebo zastaralÃ© credentials**
- Development Supabase projekt neexistuje nebo mÃ¡ jinÃ© credentials

**Å˜eÅ¡enÃ­:**
1. VytvoÅ™ novÃ½ Development Supabase projekt na https://supabase.com
2. ZkopÃ­ruj sprÃ¡vnÃ© credentials do `.env.local`:
   ```env
   DB_USER=postgres.xxxxxxxxxx
   DB_PASSWORD=your-actual-password
   DB_HOST=aws-0-eu-central-1.pooler.supabase.com
   DB_PORT=6543
   SUPABASE_URL=https://xxxxxxxxxx.supabase.co
   SUPABASE_ANON_KEY=eyJhbGc...
   ```
3. Nebo pouÅ¾ij **production credentials** doÄasnÄ›:
   ```bash
   set DJANGO_ENV=production
   python test_rag_chatbot.py
   ```

---

## ğŸ“Š Architektura RAG Chatbotu

### Jak RAG Chatbot Funguje (Teoreticky)

```
User Query
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. EMBEDDING GENERATION                 â”‚
â”‚    - User dotaz â†’ OpenAI embedding      â”‚
â”‚    - Model: text-embedding-3-small      â”‚
â”‚    - Dimension: 1536                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. SEMANTIC SEARCH (pgvector)           â”‚
â”‚    - Cosine similarity v PostgreSQL     â”‚
â”‚    - Filtr: pouze user's documents      â”‚
â”‚    - Top K results (default: 5)         â”‚
â”‚    - Similarity threshold: 0.7          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. CONTEXT BUILDING                     â”‚
â”‚    - SestavÃ­ kontext z top chunks       â”‚
â”‚    - PÅ™idÃ¡ metadata (doc, year, type)   â”‚
â”‚    - FormÃ¡tuje pro LLM                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. LLM PROMPT ENHANCEMENT               â”‚
â”‚    - System prompt + User query         â”‚
â”‚    - + Retrieved context                â”‚
â”‚    - Model: GPT-4o                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. RESPONSE WITH SOURCES                â”‚
â”‚    - AI odpovÄ›Ä                         â”‚
â”‚    - + Source citations                 â”‚
â”‚    - + Similarity scores                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ KÃ³dovÃ¡ AnalÃ½za

### âœ… CO FUNGUJE (kÃ³d je sprÃ¡vnÄ› napsanÃ½)

#### 1. **RAG Chat Service** (`chatbot/services/rag_chat_service.py`)

**SPRÃVNÄš:**
- âœ… `retrieve_context()` - VolÃ¡ `SemanticSearchService.search_by_user()`
- âœ… Filtruje podle `similarity_threshold` (0.7)
- âœ… Sestavuje kontext z DocumentChunks
- âœ… Builduje enhanced prompt s kontextem
- âœ… FormÃ¡tuje response se sources

**KÃ³d je korektnÃ­:**
```python
def retrieve_context(self, query: str, user: User, section: Optional[str] = None):
    # Performs semantic search
    hits = self.search_service.search_by_user(
        query=query,
        user=user,
        limit=self.max_context_chunks,  # 5
    )

    # Filters by similarity
    relevant_hits = [
        hit for hit in hits
        if hit.score >= self.similarity_threshold  # 0.7
    ]

    # Builds context text from chunks
    context_parts = []
    for hit in relevant_hits:
        context_parts.append(
            f"[Dokument {i}: {hit.chunk.document.filename} ({hit.chunk.document.year})]\n"
            f"{hit.chunk.content}\n"
        )
```

**âœ… ANO, vidÃ­ do databÃ¡ze** - pouÅ¾Ã­vÃ¡ `SemanticSearchService`

#### 2. **Semantic Search Service** (`rag/services/search_service.py`)

**SPRÃVNÄš:**
- âœ… `search_by_user()` - PÅ™idÃ¡vÃ¡ filter `document__owner_id = user.id`
- âœ… PouÅ¾Ã­vÃ¡ pgvector `<=>` operator pro cosine distance
- âœ… SQL query je sprÃ¡vnÄ› sestavenÃ½:

```python
def search_by_user(self, query: str, user: User, limit: int = 10):
    return self.search(
        query=query,
        user=user,
        limit=limit,
        filters={'document__owner_id': user.id},  # âœ… FILTR!
        log_query=True,
    )
```

**SQL Query:**
```sql
SELECT
    id, content, document_id, chunk_index,
    1 - (embedding <=> %s::vector) / 2 AS similarity
FROM rag_documentchunk
WHERE embedding IS NOT NULL
  AND document__owner_id = %s  -- âœ… USER FILTER
  AND (1 - (embedding <=> %s::vector) / 2) >= 0.7  -- threshold
ORDER BY embedding <=> %s::vector
LIMIT 5
```

**âœ… ANO, posÃ­lÃ¡ data z DB k OpenAI** - kontext je souÄÃ¡stÃ­ promptu

#### 3. **RAG View** (`chatbot/views_rag.py`)

**SPRÃVNÄš:**
- âœ… `/chatbot/api/rag/` endpoint
- âœ… VolÃ¡ `rag_service.generate_rag_response()`
- âœ… PosÃ­lÃ¡ enhanced prompt do OpenAI:

```python
# Builds messages with RAG context
messages = [
    {"role": "system", "content": RAG_SYSTEM_PROMPT},
    {"role": "user", "content": user_message},  # âœ… Obsahuje kontext!
]

# Calls OpenAI
completion = client.chat.completions.create(
    model=ASSISTANT_MODEL,  # gpt-4o
    messages=messages,
    temperature=0.7,
    max_tokens=1500,
)
```

**âœ… ANO, data z DB jdou do OpenAI** - jako souÄÃ¡st `user_message`

---

## âš ï¸ CO MÅ®Å½E SELHAT (ne kÃ³d, ale data)

### 1. **Å½Ã¡dnÃ© Chunky v DatabÃ¡zi**
```python
# Pokud nenÃ­ spuÅ¡tÄ›n RAG processing:
DocumentChunk.objects.count()  # â†’ 0 âŒ
```

**Kontrola:**
```bash
python manage.py shell
>>> from rag.models import DocumentChunk
>>> DocumentChunk.objects.count()
>>> DocumentChunk.objects.filter(embedding__isnull=False).count()
```

**Å˜eÅ¡enÃ­:**
```bash
python manage.py process_documents_rag
```

### 2. **Chunky Bez EmbeddingÅ¯**
```python
# Pokud embeddings selhaly:
chunks_without_embeddings = DocumentChunk.objects.filter(embedding__isnull=True).count()
```

**PÅ™Ã­Äiny:**
- OpenAI API key nenÃ­ platnÃ½
- Rate limit exceeded
- Processing byl pÅ™eruÅ¡en

### 3. **User NemÃ¡ Å½Ã¡dnÃ© Dokumenty**
```python
# Pokud user nemÃ¡ nahranÃ© PDF:
Document.objects.filter(owner=user).count()  # â†’ 0 âŒ
# Pak:
DocumentChunk.objects.filter(document__owner=user).count()  # â†’ 0 âŒ
```

**VÃ½sledek:** RAG vrÃ¡tÃ­ prÃ¡zdnÃ½ kontext

### 4. **Low Similarity Scores**
```python
# Pokud jsou vÅ¡echny chunks irelevantnÃ­:
relevant_hits = [hit for hit in hits if hit.score >= 0.7]  # â†’ [] âŒ
```

**PÅ™Ã­Äiny:**
- User dotaz je pÅ™Ã­liÅ¡ odliÅ¡nÃ½ od obsahu dokumentÅ¯
- Embeddings jsou Å¡patnÃ© kvality
- Threshold 0.7 je pÅ™Ã­liÅ¡ pÅ™Ã­snÃ½

---

## ğŸ§ª TestovacÃ­ Checklist

### Pro OvÄ›Å™enÃ­, Å½e RAG Funguje:

```bash
# 1. Zkontroluj databÃ¡zovÃ© pÅ™ipojenÃ­
python manage.py shell
>>> from django.db import connection
>>> connection.cursor()  # MÄ›lo by fungovat

# 2. Zkontroluj RAG data
>>> from rag.models import DocumentChunk
>>> DocumentChunk.objects.count()  # MÄ›lo by bÃ½t > 0
>>> DocumentChunk.objects.filter(embedding__isnull=False).count()  # > 0

# 3. Zkontroluj user documenty
>>> from django.contrib.auth import get_user_model
>>> from ingest.models import Document
>>> User = get_user_model()
>>> user = User.objects.first()
>>> Document.objects.filter(owner=user).count()  # > 0
>>> DocumentChunk.objects.filter(document__owner=user).count()  # > 0

# 4. Test semantic search
>>> from rag.services import SemanticSearchService
>>> search = SemanticSearchService()
>>> results = search.search_by_user(query="trÅ¾by", user=user, limit=3)
>>> len(results)  # MÄ›lo by bÃ½t > 0
>>> results[0].chunk.content  # MÄ›l by obsahovat relevantnÃ­ text

# 5. Test RAG service
>>> from chatbot.services import RAGChatService
>>> rag = RAGChatService()
>>> context = rag.retrieve_context(query="jakÃ© jsou trÅ¾by?", user=user)
>>> context['has_context']  # True
>>> len(context['sources'])  # > 0

# 6. Test full flow
>>> result = rag.generate_rag_response(query="jakÃ© jsou trÅ¾by?", user=user)
>>> result['has_rag_context']  # True
>>> result['prompt']  # MÄ›l by obsahovat context z dokumentÅ¯
```

---

## ğŸ“‹ AkÄnÃ­ Kroky

### OKAMÅ½ITÄš:

1. **Fix Database Connection:**
   ```bash
   # Option A: PouÅ¾ij production DB doÄasnÄ›
   set DJANGO_ENV=production
   python manage.py shell

   # Option B: VytvoÅ™ novÃ½ dev Supabase projekt
   # a updatuj .env.local
   ```

2. **SpusÅ¥ RAG Processing:**
   ```bash
   python manage.py process_documents_rag
   ```

3. **Verify Data:**
   ```bash
   python manage.py shell
   >>> from rag.models import DocumentChunk
   >>> DocumentChunk.objects.count()
   >>> DocumentChunk.objects.filter(embedding__isnull=False).count()
   ```

### POTÃ‰:

4. **Test Chatbot Endpoint:**
   ```bash
   # V browseru nebo Postman:
   POST /chatbot/api/rag/
   {
       "message": "jakÃ© jsou trÅ¾by za rok 2023?",
       "use_rag": true
   }
   ```

5. **Zkontroluj Logs:**
   ```bash
   # V Django shell:
   >>> from rag.models import SearchQuery
   >>> SearchQuery.objects.latest('created_at')
   # MÄ›lo by zobrazit poslednÃ­ search query
   ```

---

## âœ… ZÃVÄšR

### KÃ³d Je SprÃ¡vnÄ› NapsanÃ½

- âœ… RAG service **ANO, vidÃ­ do databÃ¡ze**
- âœ… Search service **ANO, filtruje podle user**
- âœ… Context **ANO, posÃ­lÃ¡ se k OpenAI**
- âœ… SQL queries **jsou sprÃ¡vnÄ›**
- âœ… Embeddings **generujÃ­ se sprÃ¡vnÄ›**

### ProblÃ©m Je V Datech/ProstÅ™edÃ­

- âŒ **DatabÃ¡ze nenÃ­ dostupnÃ¡** (.env.local credentials)
- âŒ **RAG processing moÅ¾nÃ¡ nebÄ›Å¾el** (chunky/embeddings chybÃ­)
- âŒ **User moÅ¾nÃ¡ nemÃ¡ dokumenty** (nic k prohledÃ¡vÃ¡nÃ­)

### Co Opravit

1. **DATABASE_CONNECTION** - Priorita #1
2. **RUN_RAG_PROCESSING** - Priorita #2
3. **UPLOAD_DOCUMENTS** - Priorita #3
4. **TEST_ENDPOINT** - Priorita #4

---

**PoznÃ¡mka:** KÃ³d chatbotu je **architekturÃ¡lnÄ› sprÃ¡vnÄ› navrÅ¾enÃ½**. ProblÃ©m nenÃ­ v logice, ale v missing data nebo Å¡patnÃ©m prostÅ™edÃ­.
