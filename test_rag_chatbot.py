"""
Diagnostick√Ω skript pro testov√°n√≠ RAG chatbot funkcionality
"""

import os
import django
import sys
from pathlib import Path

# Django setup
BASE_DIR = Path(__file__).resolve().parent
sys.path.insert(0, str(BASE_DIR))
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'app.settings')

try:
    django.setup()
except Exception as e:
    print(f"‚ùå Django setup failed: {e}")
    sys.exit(1)

from django.contrib.auth import get_user_model
from rag.models import DocumentChunk
from rag.services import SemanticSearchService, EmbeddingService
from chatbot.services import RAGChatService
from ingest.models import Document

User = get_user_model()


def print_section(title):
    """Print section header."""
    print(f"\n{'='*60}")
    print(f"  {title}")
    print(f"{'='*60}\n")


def test_1_database_connection():
    """Test 1: PostgreSQL a pgvector p≈ôipojen√≠"""
    print_section("TEST 1: Datab√°zov√© p≈ôipojen√≠")

    from django.db import connection

    try:
        with connection.cursor() as cursor:
            # Test pgvector extension
            cursor.execute("SELECT * FROM pg_extension WHERE extname = 'vector';")
            result = cursor.fetchone()

            if result:
                print("‚úÖ pgvector extension je nainstalov√°na")
                print(f"   Version: {result[1] if len(result) > 1 else 'N/A'}")
            else:
                print("‚ùå pgvector extension NEN√ç nainstalov√°na!")
                return False

            # Test RAG tables
            cursor.execute("""
                SELECT table_name
                FROM information_schema.tables
                WHERE table_schema = 'public'
                AND table_name LIKE 'rag_%';
            """)
            tables = cursor.fetchall()

            print(f"\nüìä RAG tabulky ({len(tables)}):")
            for table in tables:
                cursor.execute(f"SELECT COUNT(*) FROM {table[0]};")
                count = cursor.fetchone()[0]
                print(f"   - {table[0]}: {count} ≈ô√°dk≈Ø")

            return True

    except Exception as e:
        print(f"‚ùå Chyba p≈ôipojen√≠: {e}")
        return False


def test_2_document_chunks():
    """Test 2: DocumentChunk data v datab√°zi"""
    print_section("TEST 2: DocumentChunk Data")

    try:
        total_chunks = DocumentChunk.objects.count()
        chunks_with_embeddings = DocumentChunk.objects.filter(
            embedding__isnull=False
        ).count()

        print(f"üìÑ Celkem chunk≈Ø: {total_chunks}")
        print(f"üß† Chunky s embeddings: {chunks_with_embeddings}")

        if total_chunks == 0:
            print("\n‚ö†Ô∏è  ≈Ω√ÅDN√â CHUNKY V DATAB√ÅZI!")
            print("   Spus≈•: python manage.py process_documents_rag")
            return False

        if chunks_with_embeddings == 0:
            print("\n‚ö†Ô∏è  ≈Ω√ÅDN√â EMBEDDINGS!")
            print("   Zkontroluj, zda bƒõ≈æel embedding proces")
            return False

        # Sample chunk
        sample = DocumentChunk.objects.filter(embedding__isnull=False).first()
        if sample:
            print(f"\nüìù Uk√°zkov√Ω chunk (ID: {sample.id}):")
            print(f"   Dokument: {sample.document.filename}")
            print(f"   Rok: {sample.document.year}")
            print(f"   Index: {sample.chunk_index}")
            print(f"   Content: {sample.content[:100]}...")
            print(f"   Has embedding: {'‚úÖ' if sample.embedding else '‚ùå'}")

            # Check embedding dimension
            if sample.embedding:
                from rag.services.embedding_service import EmbeddingService
                emb_service = EmbeddingService()
                print(f"   Embedding dimension: {len(sample.embedding)} (oƒçek√°v√°no: {emb_service.dimension})")

        return chunks_with_embeddings > 0

    except Exception as e:
        print(f"‚ùå Chyba: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_3_semantic_search():
    """Test 3: Semantic Search funkcionalita"""
    print_section("TEST 3: Semantic Search")

    try:
        # Get a test user
        user = User.objects.filter(is_active=True).first()
        if not user:
            print("‚ùå ≈Ω√°dn√Ω aktivn√≠ u≈æivatel nenalezen!")
            return False

        print(f"üë§ Test user: {user.username} (ID: {user.id})")

        # Check user documents
        user_docs = Document.objects.filter(owner=user).count()
        user_chunks = DocumentChunk.objects.filter(document__owner=user).count()
        user_chunks_emb = DocumentChunk.objects.filter(
            document__owner=user,
            embedding__isnull=False
        ).count()

        print(f"üìÑ Dokumenty u≈æivatele: {user_docs}")
        print(f"üì¶ Chunky u≈æivatele: {user_chunks}")
        print(f"üß† Chunky s embeddings: {user_chunks_emb}")

        if user_chunks_emb == 0:
            print("\n‚ö†Ô∏è  U≈æivatel nem√° ≈æ√°dn√© chunky s embeddings!")
            print("   RAG search nebude fungovat pro tohoto u≈æivatele")
            return False

        # Test search
        print("\nüîç Testov√°n√≠ semantic search...")
        search_service = SemanticSearchService()

        test_queries = [
            "jak√© jsou tr≈æby?",
            "kolik je zisk?",
            "cash flow",
        ]

        for query in test_queries:
            print(f"\n   Query: '{query}'")
            results = search_service.search_by_user(
                query=query,
                user=user,
                limit=3,
            )

            print(f"   V√Ωsledky: {len(results)}")
            for i, hit in enumerate(results, 1):
                print(f"      {i}. Doc: {hit.chunk.document.filename} "
                      f"({hit.chunk.document.year}) "
                      f"[score: {hit.score:.3f}]")
                print(f"         Content: {hit.chunk.content[:80]}...")

        return len(results) > 0

    except Exception as e:
        print(f"‚ùå Chyba: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_4_rag_chat_service():
    """Test 4: RAG Chat Service"""
    print_section("TEST 4: RAG Chat Service")

    try:
        user = User.objects.filter(is_active=True).first()
        if not user:
            print("‚ùå ≈Ω√°dn√Ω u≈æivatel!")
            return False

        print(f"üë§ Test user: {user.username}")

        # Initialize RAG service
        rag_service = RAGChatService()
        print("‚úÖ RAGChatService inicializov√°n")

        # Test context retrieval
        test_query = "jak√© jsou finanƒçn√≠ v√Ωsledky za posledn√≠ rok?"

        print(f"\nüîç Test query: '{test_query}'")
        print("   Z√≠sk√°v√°m kontext...")

        context = rag_service.retrieve_context(
            query=test_query,
            user=user,
        )

        print(f"\nüìä V√Ωsledek:")
        print(f"   Has context: {context['has_context']}")
        print(f"   Chunks: {len(context['chunks'])}")
        print(f"   Sources: {len(context['sources'])}")

        if context['has_context']:
            print(f"\nüìù Context text:")
            print(f"   {context['context_text'][:200]}...")

            print(f"\nüìÑ Zdroje:")
            for source in context['sources']:
                print(f"      - {source['document_name']} ({source['year']}) "
                      f"[similarity: {source['similarity']:.3f}]")
        else:
            print("\n‚ö†Ô∏è  ≈Ω√°dn√Ω kontext nenalezen!")

        # Test prompt building
        print(f"\nü§ñ Generov√°n√≠ RAG response...")
        rag_result = rag_service.generate_rag_response(
            query=test_query,
            user=user,
        )

        print(f"\n   Has RAG context: {rag_result['has_rag_context']}")
        print(f"   Sources: {len(rag_result['sources'])}")
        print(f"\n   Prompt pro LLM:")
        print(f"   {rag_result['prompt'][:300]}...")

        return rag_result['has_rag_context']

    except Exception as e:
        print(f"‚ùå Chyba: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_5_openai_connection():
    """Test 5: OpenAI API p≈ôipojen√≠"""
    print_section("TEST 5: OpenAI API")

    try:
        from openai import OpenAI

        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            print("‚ùå OPENAI_API_KEY nen√≠ nastavena!")
            return False

        print(f"üîë API Key: {api_key[:20]}...{api_key[-5:]}")

        client = OpenAI(api_key=api_key)
        print("‚úÖ OpenAI client inicializov√°n")

        # Test embeddings
        print("\nüß™ Testov√°n√≠ embeddings API...")
        response = client.embeddings.create(
            model="text-embedding-3-small",
            input="test query"
        )

        embedding = response.data[0].embedding
        print(f"‚úÖ Embedding vygenerov√°n: {len(embedding)} dimensions")

        # Test chat completion
        print("\nüß™ Testov√°n√≠ chat API...")
        completion = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "user", "content": "≈òekni pouze 'test OK'"}
            ],
            max_tokens=10,
        )

        response_text = completion.choices[0].message.content.strip()
        print(f"‚úÖ Chat response: {response_text}")

        return True

    except Exception as e:
        print(f"‚ùå Chyba: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_6_full_rag_flow():
    """Test 6: Kompletn√≠ RAG flow (simulace chatbot requestu)"""
    print_section("TEST 6: Kompletn√≠ RAG Flow")

    try:
        from openai import OpenAI
        from chatbot.services import RAGChatService

        user = User.objects.filter(is_active=True).first()
        if not user:
            print("‚ùå ≈Ω√°dn√Ω u≈æivatel!")
            return False

        print(f"üë§ User: {user.username}")

        # Initialize services
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            print("‚ùå OPENAI_API_KEY nen√≠ nastavena!")
            return False

        client = OpenAI(api_key=api_key)
        rag_service = RAGChatService()

        # User query
        query = "Jak√© byly tr≈æby v roce 2023?"
        print(f"\nüí¨ Dotaz: '{query}'")

        # Step 1: RAG context retrieval
        print("\n1Ô∏è‚É£  Z√≠sk√°v√°n√≠ RAG kontextu...")
        rag_result = rag_service.generate_rag_response(
            query=query,
            user=user,
        )

        has_context = rag_result['has_rag_context']
        print(f"   Has context: {has_context}")
        print(f"   Sources: {len(rag_result['sources'])}")

        if has_context:
            for source in rag_result['sources'][:3]:
                print(f"      - {source['document_name']} ({source['year']})")

        # Step 2: LLM call with context
        print("\n2Ô∏è‚É£  Vol√°n√≠ OpenAI s kontextem...")
        messages = [
            {"role": "system", "content": "Jsi finanƒçn√≠ analytik. Odpov√≠dej ƒçesky."},
            {"role": "user", "content": rag_result['prompt']},
        ]

        completion = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            temperature=0.7,
            max_tokens=500,
        )

        response = completion.choices[0].message.content.strip()

        # Step 3: Format response with sources
        print("\n3Ô∏è‚É£  Form√°tov√°n√≠ odpovƒõdi...")
        if has_context:
            formatted = rag_service.format_response_with_sources(
                response=response,
                sources=rag_result['sources'],
            )
            final_response = formatted['response']
        else:
            final_response = response

        print(f"\n‚úÖ FIN√ÅLN√ç ODPOVƒöƒé:")
        print(f"{'='*60}")
        print(final_response)
        print(f"{'='*60}")

        return True

    except Exception as e:
        print(f"‚ùå Chyba: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """Run all tests."""
    print("\n" + "="*60)
    print("  RAG CHATBOT DIAGNOSTIKA")
    print("="*60)

    results = {}

    tests = [
        ("Database Connection", test_1_database_connection),
        ("Document Chunks", test_2_document_chunks),
        ("Semantic Search", test_3_semantic_search),
        ("RAG Chat Service", test_4_rag_chat_service),
        ("OpenAI API", test_5_openai_connection),
        ("Full RAG Flow", test_6_full_rag_flow),
    ]

    for name, test_func in tests:
        try:
            results[name] = test_func()
        except KeyboardInterrupt:
            print("\n\n‚ö†Ô∏è  Test p≈ôeru≈°en u≈æivatelem")
            break
        except Exception as e:
            print(f"\n‚ùå Neoƒçek√°van√° chyba v testu '{name}': {e}")
            import traceback
            traceback.print_exc()
            results[name] = False

    # Summary
    print_section("SOUHRN TEST≈Æ")

    passed = sum(1 for v in results.values() if v)
    total = len(results)

    for name, passed_test in results.items():
        status = "‚úÖ PASS" if passed_test else "‚ùå FAIL"
        print(f"{status}  {name}")

    print(f"\n{'='*60}")
    print(f"V√Ωsledek: {passed}/{total} test≈Ø pro≈°lo")
    print(f"{'='*60}\n")

    if passed == total:
        print("üéâ V≈†ECHNY TESTY PRO≈†LY! RAG chatbot by mƒõl fungovat spr√°vnƒõ.")
    else:
        print("‚ö†Ô∏è  NƒöKTER√â TESTY SELHALY. Zkontroluj chyby v√Ω≈°e.")
        print("\nTipy na ≈ôe≈°en√≠:")
        print("1. Spus≈• RAG processing: python manage.py process_documents_rag")
        print("2. Zkontroluj .env soubor (OPENAI_API_KEY)")
        print("3. Zkontroluj PostgreSQL p≈ôipojen√≠ a pgvector extension")
        print("4. Zkontroluj, ≈æe u≈æivatel m√° nahran√© dokumenty")


if __name__ == "__main__":
    main()
